{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4e45a6-1ed6-4e90-b0b7-913566652b40",
   "metadata": {},
   "source": [
    "### Import libraries, custom classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82038178-2699-403b-b32a-342b8d19ae98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chromadb package is not available on this system, skipping\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "from llama_index.core import ServiceContext, set_global_service_context, set_global_handler\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from task_dataset import PubMedQATaskDataset\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from utils.hosting_utils import RAGLLM\n",
    "from utils.rag_utils import (\n",
    "    DocumentReader, RAGEmbedding, RAGQueryEngine, RagasEval, \n",
    "    extract_yes_no, evaluate, validate_rag_cfg\n",
    "    )\n",
    "from utils.storage_utils import RAGIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c656caf6-8303-46ca-9336-ca2352fb3512",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path.home() / \".cohere_api_key\", \"r\") as f:\n",
    "    os.environ[\"COHERE_API_KEY\"] = f.read().rstrip(\"\\n\")\n",
    "with open(Path.home() / \".hfhub_api_token\", \"r\") as f:\n",
    "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = f.read().rstrip(\"\\n\")\n",
    "with open(Path.home() / \".openai_api_key\", \"r\") as f:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read().rstrip(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70d889-6e10-45b7-be3b-52a5b56d4f43",
   "metadata": {},
   "source": [
    "### Set RAG configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab816260-2e3f-4ac3-a3f7-623202b116bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_cfg = {\n",
    "    # Node parser config\n",
    "    \"chunk_size\": 256,\n",
    "    \"chunk_overlap\": 0,\n",
    "\n",
    "    # Embedding model config\n",
    "    \"embed_model_type\": \"hf\",\n",
    "    \"embed_model_name\": \"BAAI/bge-base-en-v1.5\",\n",
    "\n",
    "    # LLM config\n",
    "    \"llm_type\": \"local\",\n",
    "    \"llm_name\": \"Llama-2-7b-chat-hf\",\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"temperature\": 1.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"top_k\": 50,\n",
    "    \"do_sample\": False,\n",
    "\n",
    "    # Vector DB config\n",
    "    \"vector_db_type\": \"weaviate\", # \"chromadb\", \"weaviate\"\n",
    "    \"vector_db_name\": \"Pubmed_QA\",\n",
    "    # MODIFY THIS\n",
    "    \"weaviate_url\": \"https://rag-bootcamp-pubmed-qa-lsqv7od4.weaviate.network\",\n",
    "\n",
    "    # Retriever and query config\n",
    "    \"retriever_type\": \"bm25\", # \"vector_index\", \"bm25\"\n",
    "    \"retriever_similarity_top_k\": 3,\n",
    "    \"query_mode\": \"hybrid\", # \"default\", \"hybrid\"\n",
    "    \"hybrid_search_alpha\": 0.5, # float from 0.0 (sparse search - bm25) to 1.0 (vector search)\n",
    "    \"response_mode\": \"compact\",\n",
    "    \"use_reranker\": True,\n",
    "    \"rerank_top_k\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbccb34-cf49-4661-bdb5-589e25e02d95",
   "metadata": {},
   "source": [
    "### Weaviate Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2f405b-4c51-4174-ae8b-03029adec4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = open(Path.home() / \".weaviate_api_key\", \"r\")\n",
    "    f.close()\n",
    "except Exception as err:\n",
    "    print(f\"Could not read your Weaviate key. Please make sure this is available in plain text under your home directory in ~/.weaviate_api_key: {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63ff4f-fdcb-48db-8c88-87b602fb0f86",
   "metadata": {},
   "source": [
    "## STAGE 0 - Preliminary config checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08e83dc8-9449-41d6-899d-0189bacaf437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk_overlap': 0,\n",
      " 'chunk_size': 256,\n",
      " 'do_sample': False,\n",
      " 'embed_model_name': 'BAAI/bge-base-en-v1.5',\n",
      " 'embed_model_type': 'hf',\n",
      " 'hybrid_search_alpha': 0.5,\n",
      " 'llm_name': 'Llama-2-7b-chat-hf',\n",
      " 'llm_type': 'local',\n",
      " 'max_new_tokens': 256,\n",
      " 'query_mode': 'hybrid',\n",
      " 'rerank_top_k': 2,\n",
      " 'response_mode': 'compact',\n",
      " 'retriever_similarity_top_k': 3,\n",
      " 'retriever_type': 'bm25',\n",
      " 'temperature': 1.0,\n",
      " 'top_k': 50,\n",
      " 'top_p': 1.0,\n",
      " 'use_reranker': True,\n",
      " 'vector_db_name': 'Pubmed_QA',\n",
      " 'vector_db_type': 'weaviate',\n",
      " 'weaviate_url': 'https://rag-bootcamp-pubmed-qa-lsqv7od4.weaviate.network'}\n"
     ]
    }
   ],
   "source": [
    "pprint(rag_cfg)\n",
    "validate_rag_cfg(rag_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8672715b-12b7-424d-8410-859ff336a757",
   "metadata": {},
   "source": [
    "## STAGE 1 - Load dataset and documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5fd2a-f974-4bb5-a678-7110aba1bc32",
   "metadata": {},
   "source": [
    "#### 1. Load PubMed QA dataset\n",
    "PubMedQA ([github](https://github.com/pubmedqa/pubmedqa)) is a biomedical question answering dataset. Each instance consists of a question, a context (extracted from PubMed abstracts), a long answer and a yes/no/maybe answer. We make use of the test split of [this](https://huggingface.co/datasets/bigbio/pubmed_qa) huggingface dataset for this notebook.\n",
    "\n",
    "**The context for each instance is stored as a text file** (referred to as documents), to align the task as a standard RAG use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd814ec-3084-4a5f-9fa9-8def165fe77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PubMed QA data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|██████████| 500/500 [00:00<00:00, 1400.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data size: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading PubMed QA data ...')\n",
    "pubmed_data = PubMedQATaskDataset('bigbio/pubmed_qa')\n",
    "print(f\"Loaded data size: {len(pubmed_data)}\")\n",
    "# pubmed_data.mock_knowledge_base(output_dir='./data', one_file_per_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139f09c-bf13-4d4a-9637-c7be7e165ad8",
   "metadata": {},
   "source": [
    "#### 2. Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b8ff42-45ee-4ad2-bf72-ccca100e1286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents ...\n",
      "No. of documents loaded: 500\n"
     ]
    }
   ],
   "source": [
    "print('Loading documents ...')\n",
    "reader = DocumentReader(input_dir=\"./data/pubmed_doc\")\n",
    "docs = reader.load_data()\n",
    "print(f'No. of documents loaded: {len(docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db76ff-1c8c-4ada-8c3d-30b2ef7bca30",
   "metadata": {},
   "source": [
    "## STAGE 2 - Load node parser, embedding, LLM and set service context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e540f6-2522-4d69-89e6-3233f665c589",
   "metadata": {},
   "source": [
    "#### 1. Load node parser to split documents into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd11331-fe79-4100-bcd9-127838159e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading node parser ...\n"
     ]
    }
   ],
   "source": [
    "print('Loading node parser ...')\n",
    "node_parser = SentenceSplitter(chunk_size=rag_cfg['chunk_size'], chunk_overlap=rag_cfg['chunk_overlap'])\n",
    "# nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b8905-8a8e-4495-90f4-4e69811d9d19",
   "metadata": {},
   "source": [
    "#### 2. Load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cae31175-725c-46f9-ae43-5dc80f604649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hf embedding model ...\n"
     ]
    }
   ],
   "source": [
    "embed_model = RAGEmbedding(model_type=rag_cfg['embed_model_type'], model_name=rag_cfg['embed_model_name']).load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6446adf-983e-451c-b5dd-9a178e3b1af7",
   "metadata": {},
   "source": [
    "#### 3. Load LLM for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d99126d7-48d6-4551-9c64-2044f7962ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local LLM model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb5cd2a831249f09ddfc838034fcb3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = RAGLLM(rag_cfg['llm_type'], rag_cfg['llm_name']).load_model(**rag_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb554bd-9df1-444c-b75a-373e117eee06",
   "metadata": {},
   "source": [
    "#### 4. Use service context to set the node parser, embedding model, LLM, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c62a809-0558-4e29-ae0d-451259663f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5861/1984815513.py:1: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    node_parser=node_parser,\n",
    "    embed_model=embed_model,\n",
    "    llm=llm,\n",
    ")\n",
    "# Set it globally to avoid passing it to every class, this sets it even for rag_utils.py\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dceb1e4-5ed6-47cb-987f-93f186387269",
   "metadata": {},
   "source": [
    "## STAGE 3 - Create index using the appropriate vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23824c74-c247-46ff-86fc-dcf1a8bd6fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from ./.weaviate_index_store/ ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/home/odige/rag_bootcamp/envs/rag_pubmed_qa_env/lib/python3.10/site-packages/weaviate/warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.4.4.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "index = RAGIndex(db_type=rag_cfg['vector_db_type'], db_name=rag_cfg['vector_db_name'])\\\n",
    "    .create_index(docs, weaviate_url=rag_cfg[\"weaviate_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175a4a5-0a66-41b3-a848-850ce048bc6c",
   "metadata": {},
   "source": [
    "## STAGE 4 - Build query engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d105b-87ca-4bac-a1b0-254f73297b0d",
   "metadata": {},
   "source": [
    "Now build a query engine using *retriever* and *response_synthesizer*  \n",
    "[Weaviate hybrid search](https://weaviate.io/blog/hybrid-search-explained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f47bc0bd-3d83-4dce-b488-38806eed654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_args = {\n",
    "    \"similarity_top_k\": rag_cfg['retriever_similarity_top_k'], \n",
    "    \"response_mode\": rag_cfg['response_mode'],\n",
    "}\n",
    "\n",
    "if (rag_cfg[\"retriever_type\"] == \"vector_index\") and (rag_cfg[\"vector_db_type\"] == \"weaviate\"):\n",
    "    query_engine_args.update({\n",
    "        \"query_mode\": rag_cfg[\"query_mode\"], \n",
    "        \"hybrid_search_alpha\": rag_cfg[\"hybrid_search_alpha\"]\n",
    "    })\n",
    "elif rag_cfg[\"retriever_type\"] == \"bm25\":\n",
    "    nodes = service_context.node_parser.get_nodes_from_documents(docs)\n",
    "    tokenizer = service_context.embed_model._tokenizer\n",
    "    query_engine_args.update({\"nodes\": nodes, \"tokenizer\": tokenizer})\n",
    "    \n",
    "if rag_cfg[\"use_reranker\"]:\n",
    "    query_engine_args.update({\"use_reranker\": True, \"rerank_top_k\": rag_cfg[\"rerank_top_k\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5502edfd-75d0-4b48-b75d-46e6adf9447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RAGQueryEngine(\n",
    "    retriever_type=rag_cfg['retriever_type'], vector_index=index, llm_model_name=rag_cfg['llm_name']).create(**query_engine_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6df972-2515-4968-9ea9-e2604f6ab82a",
   "metadata": {},
   "source": [
    "## STAGE 5 - Finally query the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd7abee9-59f7-481b-a644-45c107d10686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': ['no'],\n",
      " 'context': 'Human immunodeficiency virus (HIV)-infected patients have '\n",
      "            'generally been excluded from transplantation. Recent advances in '\n",
      "            'the management and prognosis of these patients suggest that this '\n",
      "            'policy should be reevaluated. To explore the current views of '\n",
      "            'U.S. transplant centers toward transplanting asymptomatic '\n",
      "            'HIV-infected patients with end-stage renal disease, a written '\n",
      "            'survey was mailed to the directors of transplantation at all 248 '\n",
      "            'renal transplant centers in the United States. All 148 responding '\n",
      "            'centers said they require HIV testing of prospective kidney '\n",
      "            'recipients, and 84% of these centers would not transplant an '\n",
      "            'individual who refuses HIV testing. The vast majority of '\n",
      "            'responding centers would not transplant a kidney from a cadaveric '\n",
      "            '(88%) or a living donor (91%) into an asymptomatic HIV-infected '\n",
      "            'patient who is otherwise a good candidate for transplantation. '\n",
      "            'Among the few centers that would consider transplanting an '\n",
      "            'HIV-infected patient, not a single center had performed such a '\n",
      "            'transplant in the year prior to the survey. Most centers fear '\n",
      "            'that transplantation in the face of HIV infection would be '\n",
      "            'harmful to the individual, and some believe that it would be a '\n",
      "            'waste of precious organs.',\n",
      " 'id': '9603166',\n",
      " 'long_answer': 'The great majority of U.S. renal transplant centers will not '\n",
      "                'transplant kidneys to HIV-infected patients with end-stage '\n",
      "                'renal disease, even if their infection is asymptomatic. '\n",
      "                'However, advances in the management of HIV infection and a '\n",
      "                'review of relevant ethical issues suggest that this approach '\n",
      "                'should be reconsidered.',\n",
      " 'question': 'Should all human immunodeficiency virus-infected patients with '\n",
      "             'end-stage renal disease be excluded from transplantation?'}\n"
     ]
    }
   ],
   "source": [
    "random.seed(237)\n",
    "sample_idx = random.randint(0, len(pubmed_data)-1)\n",
    "sample_elm = pubmed_data[sample_idx]\n",
    "pprint(sample_elm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8279db69-6525-401a-b39c-69f6b83cb0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: Should all human immunodeficiency virus-infected patients with end-stage renal disease be excluded from transplantation?\n",
      "RESPONSE:  Based on the context information provided, I cannot make a direct answer to your query as it is not directly related to the study or the discharge coordinator's role. The study focused on the effectiveness of a discharge coordinator in improving the quality of discharge planning for medical ward patients, and did not investigate the eligibility of patients for transplantation. Therefore, I cannot provide an answer to your query.\n",
      "However, I can tell you that the decision to exclude patients from transplantation is a complex one that depends on various factors, including the patient's medical history, current health status, and the availability of organs for transplantation. It is important to consult with a medical professional to determine the most appropriate course of action for each individual patient.\n",
      "In summary, I cannot answer your query based on the context information provided, and I recommend consulting with a medical professional for personalized advice.\n",
      "Yes/No\n",
      "YES/NO: Yes\n",
      "GT ANSWER: ['no']\n",
      "GT LONG ANSWER: The great majority of U.S. renal transplant centers will not transplant kidneys to HIV-infected patients with end-stage renal disease, even if their infection is asymptomatic. However, advances in the management of HIV infection and a review of relevant ethical issues suggest that this approach should be reconsidered.\n"
     ]
    }
   ],
   "source": [
    "query = sample_elm['question']\n",
    "\n",
    "response = query_engine.query(query)\n",
    "\n",
    "print(f'QUERY: {query}')\n",
    "print(f'RESPONSE: {response}')\n",
    "print(f'YES/NO: {extract_yes_no(response.response)}')\n",
    "print(f'GT ANSWER: {sample_elm[\"answer\"]}')\n",
    "print(f'GT LONG ANSWER: {sample_elm[\"long_answer\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d78461a-97fc-4a69-8503-7a111d12bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = query_engine.retriever.retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1808e94-337b-4e4b-9637-2b79746ddddc",
   "metadata": {},
   "source": [
    "## Ragas evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bdb6372-9364-4bd3-9b81-bf403f0bc006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "passing column names as 'ground_truths' is deprecated and will be removed in the next version, please use 'ground_truth' instead. Note that `ground_truth` should be of type string and not Sequence[string] like `ground_truths`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7282535bdae94b71ad45e0682ef8a4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/home/odige/rag_bootcamp/envs/rag_pubmed_qa_env/lib/python3.10/site-packages/pydantic/main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/fs01/home/odige/rag_bootcamp/envs/rag_pubmed_qa_env/lib/python3.10/site-packages/pydantic/main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/fs01/home/odige/rag_bootcamp/envs/rag_pubmed_qa_env/lib/python3.10/site-packages/pydantic/main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/fs01/home/odige/rag_bootcamp/envs/rag_pubmed_qa_env/lib/python3.10/site-packages/pydantic/main.py:1024: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.6/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.5000, 'answer_relevancy': 0.0000, 'context_recall': 0.0000, 'context_precision': 0.0000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fs01/home/odige/rag_bootcamp/envs/rag_pubmed_qa_env/lib/python3.10/site-packages/ragas/_analytics.py:72: ResourceWarning: unclosed file <_io.TextIOWrapper name='/h/odige/.local/share/ragas/uuid.json' mode='r' encoding='UTF-8'>\n",
      "  user_id = json.load(open(uuid_filepath))[\"userid\"]\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "eval_data = {\n",
    "    \"question\": [query],\n",
    "    \"answer\": [response.response],\n",
    "    \"contexts\": [[node.text for node in retrieved_nodes]],\n",
    "    \"ground_truths\": [[sample_elm['long_answer']]],\n",
    "    }\n",
    "eval_obj = RagasEval(metrics=[\"faithfulness\", \"relevancy\", \"recall\", \"precision\"])\n",
    "eval_result = eval_obj.evaluate(eval_data)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0582ac-b840-457d-86eb-4aa9d8fc43de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67df31b4-8dd3-4352-ae30-ebfc842c4418",
   "metadata": {},
   "source": [
    "#### [WIP] Run evaluation on all samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
