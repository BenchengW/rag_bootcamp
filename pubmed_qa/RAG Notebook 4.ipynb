{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d4e45a6-1ed6-4e90-b0b7-913566652b40",
   "metadata": {},
   "source": [
    "### Import libraries, custom classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82038178-2699-403b-b32a-342b8d19ae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "from llama_index import ServiceContext, set_global_service_context, set_global_handler\n",
    "from llama_index.text_splitter import SentenceSplitter\n",
    "\n",
    "from task_dataset import PubMedQATaskDataset\n",
    "from rag_utils import (\n",
    "    DocumentReader, RAGEmbedding, RAGLLM, RAGIndex, RAGQueryEngine, \n",
    "    extract_yes_no, evaluate, validate_rag_cfg\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c70d889-6e10-45b7-be3b-52a5b56d4f43",
   "metadata": {},
   "source": [
    "### Set RAG configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab816260-2e3f-4ac3-a3f7-623202b116bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_cfg = {\n",
    "    # Node parser config\n",
    "    \"chunk_size\": 256,\n",
    "    \"chunk_overlap\": 0,\n",
    "\n",
    "    # Embedding model config\n",
    "    \"embed_model_type\": \"hf\",\n",
    "    \"embed_model_name\": \"BAAI/bge-base-en-v1.5\",\n",
    "\n",
    "    # LLM config\n",
    "    \"llm_type\": \"local\",\n",
    "    \"llm_name\": \"Llama-2-7b-chat-hf\",\n",
    "    \"max_new_tokens\": 256,\n",
    "    \"temperature\": 1.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"top_k\": 50,\n",
    "    \"do_sample\": False,\n",
    "\n",
    "    # Vector DB config\n",
    "    \"vector_db_type\": \"weaviate\", # \"chromadb\", \"weaviate\"\n",
    "    \"vector_db_name\": \"Pubmed_QA\",\n",
    "    # MODIFY THIS\n",
    "    \"weaviate_url\": \"https://vector-rag-lab-xsxuylwh.weaviate.network\",\n",
    "\n",
    "    # Retriever and query config\n",
    "    \"retriever_type\": \"vector_index\",\n",
    "    \"retriever_similarity_top_k\": 3,\n",
    "    \"query_mode\": \"hybrid\", # \"default\", \"hybrid\"\n",
    "    \"hybrid_search_alpha\": 1.0, # float from 0.0 (sparse search - bm25) to 1.0 (vector search)\n",
    "    \"response_mode\": \"compact\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63ff4f-fdcb-48db-8c88-87b602fb0f86",
   "metadata": {},
   "source": [
    "## STAGE 0 - Preliminary config checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e83dc8-9449-41d6-899d-0189bacaf437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk_overlap': 0,\n",
      " 'chunk_size': 256,\n",
      " 'do_sample': False,\n",
      " 'embed_model_name': 'BAAI/bge-base-en-v1.5',\n",
      " 'embed_model_type': 'hf',\n",
      " 'hybrid_search_alpha': 1.0,\n",
      " 'llm_name': 'Llama-2-7b-chat-hf',\n",
      " 'llm_type': 'local',\n",
      " 'max_new_tokens': 256,\n",
      " 'query_mode': 'hybrid',\n",
      " 'response_mode': 'compact',\n",
      " 'retriever_similarity_top_k': 3,\n",
      " 'retriever_type': 'vector_index',\n",
      " 'temperature': 1.0,\n",
      " 'top_k': 50,\n",
      " 'top_p': 1.0,\n",
      " 'vector_db_name': 'Pubmed_QA',\n",
      " 'vector_db_type': 'weaviate',\n",
      " 'weaviate_url': 'https://vector-rag-lab-xsxuylwh.weaviate.network'}\n"
     ]
    }
   ],
   "source": [
    "pprint(rag_cfg)\n",
    "validate_rag_cfg(rag_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8672715b-12b7-424d-8410-859ff336a757",
   "metadata": {},
   "source": [
    "## STAGE 1 - Load dataset and documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5fd2a-f974-4bb5-a678-7110aba1bc32",
   "metadata": {},
   "source": [
    "#### 1. Load PubMed QA dataset\n",
    "PubMedQA ([github](https://github.com/pubmedqa/pubmedqa)) is a biomedical question answering dataset. Each instance consists of a question, a context (extracted from PubMed abstracts), a long answer and a yes/no/maybe answer. We make use of the test split of [this](https://huggingface.co/datasets/bigbio/pubmed_qa) huggingface dataset for this notebook.\n",
    "\n",
    "**The context for each instance is stored as a text file** (referred to as documents), to align the task as a standard RAG use-case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd814ec-3084-4a5f-9fa9-8def165fe77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PubMed QA data ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|██████████| 500/500 [00:00<00:00, 1373.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data size: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Loading PubMed QA data ...')\n",
    "pubmed_data = PubMedQATaskDataset('bigbio/pubmed_qa')\n",
    "print(f\"Loaded data size: {len(pubmed_data)}\")\n",
    "# pubmed_data.mock_knowledge_base(output_dir='./data', one_file_per_sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139f09c-bf13-4d4a-9637-c7be7e165ad8",
   "metadata": {},
   "source": [
    "#### 2. Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b8ff42-45ee-4ad2-bf72-ccca100e1286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents ...\n",
      "No. of documents loaded: 500\n"
     ]
    }
   ],
   "source": [
    "print('Loading documents ...')\n",
    "reader = DocumentReader(input_dir=\"./data/pubmed_doc\")\n",
    "docs = reader.load_data()\n",
    "print(f'No. of documents loaded: {len(docs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db76ff-1c8c-4ada-8c3d-30b2ef7bca30",
   "metadata": {},
   "source": [
    "## STAGE 2 - Load node parser, embedding, LLM and set service context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e540f6-2522-4d69-89e6-3233f665c589",
   "metadata": {},
   "source": [
    "#### 1. Load node parser to split documents into smaller chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd11331-fe79-4100-bcd9-127838159e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading node parser ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "print('Loading node parser ...')\n",
    "node_parser = SentenceSplitter(chunk_size=rag_cfg['chunk_size'], chunk_overlap=rag_cfg['chunk_overlap'])\n",
    "# nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018b8905-8a8e-4495-90f4-4e69811d9d19",
   "metadata": {},
   "source": [
    "#### 2. Load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae31175-725c-46f9-ae43-5dc80f604649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading hf embedding model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668c303a6f174688a9d124db7665d613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/777 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ffd8e0a86fc4dd29209fe90be649627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d22b3d78e04460e9677209863686d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de09ab6e09154c5c983e24d2ba767991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3568cf3c07ed414ea791b606ff9fc3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa714ca41b874502ab0f77ceae8748c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embed_model = RAGEmbedding(model_type=rag_cfg['embed_model_type'], model_name=rag_cfg['embed_model_name']).load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6446adf-983e-451c-b5dd-9a178e3b1af7",
   "metadata": {},
   "source": [
    "#### 3. Load LLM for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99126d7-48d6-4551-9c64-2044f7962ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local LLM model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3908aa6e6f34c49aef6c9a52c41f2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = RAGLLM(rag_cfg['llm_type'], rag_cfg['llm_name']).load_model(**rag_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb554bd-9df1-444c-b75a-373e117eee06",
   "metadata": {},
   "source": [
    "#### 4. Use service context to set the node parser, embedding model, LLM, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c62a809-0558-4e29-ae0d-451259663f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_context = ServiceContext.from_defaults(\n",
    "    node_parser=node_parser,\n",
    "    embed_model=embed_model,\n",
    "    llm=llm,\n",
    ")\n",
    "# Set it globally to avoid passing it to every class, this sets it even for rag_utils.py\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dceb1e4-5ed6-47cb-987f-93f186387269",
   "metadata": {},
   "source": [
    "## STAGE 3 - Create index using the appropriate vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23824c74-c247-46ff-86fc-dcf1a8bd6fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading index from ./.weaviate_index_store/ ...\n"
     ]
    }
   ],
   "source": [
    "index = RAGIndex(db_type=rag_cfg['vector_db_type'], db_name=rag_cfg['vector_db_name'])\\\n",
    "    .create_index(docs, weaviate_url=rag_cfg[\"weaviate_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b175a4a5-0a66-41b3-a848-850ce048bc6c",
   "metadata": {},
   "source": [
    "## STAGE 4 - Build query engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d105b-87ca-4bac-a1b0-254f73297b0d",
   "metadata": {},
   "source": [
    "Now build a query engine using *retriever* and *response_synthesizer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f47bc0bd-3d83-4dce-b488-38806eed654f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RAGQueryEngine(\n",
    "    retriever_type=rag_cfg['retriever_type'], vector_index=index, llm_model_name=rag_cfg['llm_name']).create(\n",
    "        similarity_top_k=rag_cfg['retriever_similarity_top_k'], response_mode=rag_cfg['response_mode'], \n",
    "        query_mode=rag_cfg[\"query_mode\"], hybrid_search_alpha=rag_cfg[\"hybrid_search_alpha\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6df972-2515-4968-9ea9-e2604f6ab82a",
   "metadata": {},
   "source": [
    "## STAGE 5 - Finally query the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd7abee9-59f7-481b-a644-45c107d10686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': ['yes'],\n",
      " 'context': 'There is controversy surrounding the optimal management of the '\n",
      "            'testicular remnant associated with the vanishing testes syndrome. '\n",
      "            'Some urologists advocate the need for surgical exploration, '\n",
      "            'whereas others believe this is unnecessary. These differing '\n",
      "            'opinions are based on the variable reports of viable germ cell '\n",
      "            'elements found within the testicular remnants. To better '\n",
      "            'understand the pathology associated with this syndrome and the '\n",
      "            'need for surgical management, we reviewed our experience '\n",
      "            'regarding the incidence of viable germ cell elements within the '\n",
      "            'testicular remnant. An institutional review board-approved, '\n",
      "            'retrospective review was performed of all consecutive patients '\n",
      "            'undergoing exploration for a nonpalpable testis at Eastern '\n",
      "            'Virginia Medical School and Geisinger Medical Center between 1994 '\n",
      "            'and 2006. Patients who were found to have spermatic vessels and a '\n",
      "            'vas deferens exiting a closed internal inguinal ring were '\n",
      "            'included in this analysis. Fifty-six patients underwent removal '\n",
      "            'of the testicular remnant. Patient age ranged from 11 to 216 '\n",
      "            'months. In 8 of the specimens (14%), we identified viable germ '\n",
      "            'cell elements. In an additional 4 patients (7%), we identified '\n",
      "            'seminiferous tubules without germ cell elements.',\n",
      " 'id': '18158048',\n",
      " 'long_answer': 'In our review, we identified that a significant number of '\n",
      "                'testicular remnants associated with the vanishing testes '\n",
      "                'syndrome can harbor viable germ cell elements or seminiferous '\n",
      "                'tubules. The exact fate of these residual elements remains '\n",
      "                'unknown; however, there may exist the potential for malignant '\n",
      "                'transformation. Given the potential for malignant '\n",
      "                'degeneration, we believe that these remnants should be '\n",
      "                'removed.',\n",
      " 'question': 'Histologic evaluation of the testicular remnant associated with '\n",
      "             'the vanishing testes syndrome: is surgical management necessary?'}\n"
     ]
    }
   ],
   "source": [
    "random.seed(41)\n",
    "sample_idx = random.randint(0, len(pubmed_data)-1)\n",
    "sample_elm = pubmed_data[sample_idx]\n",
    "pprint(sample_elm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8279db69-6525-401a-b39c-69f6b83cb0af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: Histologic evaluation of the testicular remnant associated with the vanishing testes syndrome: is surgical management necessary?\n",
      "RESPONSE:  Based on the context information provided, I would answer the query as follows:\n",
      "Yes.\n",
      "The study suggests that histologic evaluation of the testicular remnant associated with the vanishing testes syndrome may be necessary for several reasons:\n",
      "1. Variable reports of viable germ cell elements: The study found that 14% of the testicular remnants had viable germ cell elements, which suggests that histologic evaluation may be necessary to determine the presence of these elements and the potential for fertility.\n",
      "2. Controversy surrounding management: The study highlights the controversy among urologists regarding the need for surgical management of the testicular remnant, with some advocating for exploration and others believing it to be unnecessary. Histologic evaluation may help to resolve this controversy by providing a more accurate assessment of the testicular remnant.\n",
      "3. Potential for malignancy: The study notes that malignancy has been reported in some cases of vanishing testes syndrome, highlighting the importance of histologic evaluation to rule out any potential malignancies.\n",
      "Overall, based on the context information provided, it appears that histologic evaluation of the test\n",
      "YES/NO: Yes\n",
      "GT ANSWER: ['yes']\n",
      "GT LONG ANSWER: In our review, we identified that a significant number of testicular remnants associated with the vanishing testes syndrome can harbor viable germ cell elements or seminiferous tubules. The exact fate of these residual elements remains unknown; however, there may exist the potential for malignant transformation. Given the potential for malignant degeneration, we believe that these remnants should be removed.\n"
     ]
    }
   ],
   "source": [
    "query = sample_elm['question']\n",
    "\n",
    "response = query_engine.query(query)\n",
    "\n",
    "print(f'QUERY: {query}')\n",
    "print(f'RESPONSE: {response}')\n",
    "print(f'YES/NO: {extract_yes_no(response.response)}')\n",
    "print(f'GT ANSWER: {sample_elm[\"answer\"]}')\n",
    "print(f'GT LONG ANSWER: {sample_elm[\"long_answer\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67df31b4-8dd3-4352-ae30-ebfc842c4418",
   "metadata": {},
   "source": [
    "#### Run evaluation on all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe8b7c50-df3d-457a-88bd-e52cd8fa136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_dict = evaluate(pubmed_data, query_engine)\n",
    "# output_dict = {\n",
    "#     \"num_samples\": len(pubmed_data),\n",
    "#     \"config\": rag_cfg,\n",
    "#     \"result\": result_dict,\n",
    "# }\n",
    "# pprint(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c703df06-d5a6-4b63-8ad2-c1ebff077b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'config': {'chunk_overlap': 0,\n",
    "#         'chunk_size': 256,\n",
    "#         'do_sample': False,\n",
    "#         'embed_model_name': 'BAAI/bge-base-en-v1.5',\n",
    "#         'embed_model_type': 'hf',\n",
    "#         'hybrid_search_alpha': 1.0,\n",
    "#         'llm_name': 'Llama-2-7b-chat-hf',\n",
    "#         'llm_type': 'local',\n",
    "#         'max_new_tokens': 256,\n",
    "#         'query_mode': 'hybrid',\n",
    "#         'response_mode': 'compact',\n",
    "#         'retriever_similarity_top_k': 3,\n",
    "#         'retriever_type': 'vector_index',\n",
    "#         'temperature': 1.0,\n",
    "#         'top_k': 50,\n",
    "#         'top_p': 1.0,\n",
    "#         'vector_db_name': 'Pubmed_QA',\n",
    "#         'vector_db_type': 'weaviate',\n",
    "#         'weaviate_url': 'https://vector-rag-lab-xsxuylwh.weaviate.network'},\n",
    "# 'num_samples': 500,\n",
    "# 'result': {'acc': 0.666, 'retriever_acc': 0.994}}\n",
    "# same as above for {'chunk_overlap': 32, 'chunk_size': 128,}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
